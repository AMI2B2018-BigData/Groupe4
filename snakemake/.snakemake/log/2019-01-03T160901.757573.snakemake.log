Building DAG of jobs...
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	merge_sort
	2

rule merge_sort:
    input: Cornell_results
    output: resultat_sort.txt
    jobid: 834

Error in rule merge_sort:
    jobid: 834
    output: resultat_sort.txt

RuleException:
CalledProcessError in line 65 of /home/martin/Documents/M2-AMI2B/bigdata/Workflow-ProjectV2/snakemake/Snakefile:
Command ' set -euo pipefail;  paste -d "
" Cornell_results* | sort  +1n -t ":" > resultat_sort.txt ' returned non-zero exit status 1.
  File "/home/martin/Documents/M2-AMI2B/bigdata/Workflow-ProjectV2/snakemake/Snakefile", line 65, in __rule_merge_sort
  File "/usr/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Removing output files of failed job merge_sort since they might be corrupted:
resultat_sort.txt
Will exit after finishing currently running jobs.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2019-01-03T160901.757573.snakemake.log
